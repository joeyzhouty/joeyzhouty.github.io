<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html>
    <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="description" content="">
    <meta name="author" content="">
    <!-- <link rel="icon" href="../../favicon.ico"> -->

     <title>CEG5304/EE6934 Deep Learning</title>
 
    <!-- Bootstrap core CSS -->
    <link href="../../bootstrap-3.3.6-dist/css/bootstrap.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="../../jumbotron.css" rel="stylesheet">
  </head>
<style>
table {
  border-collapse: collapse;
  width: 100%;
}

th, td {
  text-align: left;
  padding: 8px;
}

tr:nth-child(even) {
  background-color: #D6EEEE;
}
</style>

 <body>
     <nav class="navbar navbar-inverse navbar-fixed-top">
      
    </nav>
<!-- Main jumbotron for a primary marketing message or call to action -->
    <div class="jumbotron">
      <div class="container"  style="font-size:16px">
	
        <h2><a target="_blank" href="https://nusmods.com/modules/CEG5304/deep-learning-for-digitalization-technologies">[ECG5304] - Deep Learning for Digitalization Technologies</a> / <a target="_blank" href="https://nusmods.com/modules/EE6934/deep-learning-advanced">[EE5934/6934] - Deep Learning</a> (Part 1)</h2>
	<p>
	  Electrical and Computer Engineering, NUS
	</p>
      </div>
    </div>
    <div class="container" style="font-size:16px">
      <h3>Description:</h3>
      <p>
	This course is about  deep learning.
	Students taking this course will learn the 
	theories, models, algorithms, and recent progress of deep
	learning. The course starts
	with machine learning basics and classical neural network
	models, followed by deep convolutional neural networks,
	recurrent neural networks, reinforcement learning, etc., and
	their applications. 
	Students are expected to have good knowledge of calculus,
	linear algebra, probability and statistics as prerequisites.
      </p>
      <p>
	This website contains only information of Part 1 (the first
	half of the course).
      </p>
      <hr>
       <b>Textbooks</b> (The textbooks are used loosely):
       <ul>
       <li> <a href="https://www.deeplearningbook.org//"
       target="_blank">Deep Learning</a>, Ian Goodfellow and Yoshua
	 Bengio and Aaron Courville.
       <li> <a href="https://d2l.ai/index.html" target="_blank">Dive into Deep Learning</a>, Zhang et al.
       </ul>

      <b>Instructor</b>: <a href="https://joeyzhouty.github.io/"
      target="_blank">Joey Tianyi  
	Zhou</a>
      <br>
      <hr>

      <h3>Teaching Schedule:</h3>
<p>
The following schedule will not be strictly followed.
</p>


	    
<table width="80%" 
       border = "0"
       class="table table-striped">
  <thead class="thead-inverse">
    
 <tr>
      <th width="12%"> Date
      <th> <center> Topic </center> 
      <th width="25%"> <center> Notes </center>
  </thead>
  <tbody>
    
    
    <!------------------------------------------------------------------------------>	  
    
    
    <tr>
      <td rowspan="1"> Week 1
      <td>
	
	<b> 1.  Introduction to Deep Learning  </b>
	<br>
	<br>
 <!-- 	Additional resources (optional):
	<ul>
	  <li> Introduction to Machine Learning:
	  <a href="http://www.cs.princeton.edu/courses/archive/spr08/cos511/scribe_notes/0204.pdf"
	  target="_blank">pdf</a> | <a href="https://www.youtube.com/watch?v=cKxRvEZd3Mw" target="_blank">youtube</a>
	</ul>
	<br>
-->
      <td align="left">
	<a target="_blank"> Machine Learning Basics. Data Pre-processing.</a>
   </tr>
    
    <!------------------------------------------------------------------------------>
    
    
    <tr>
      <td rowspan="1"> Week 2
      <td>
	<b> 2. Neural networks, training pipeline and learning strategies </b>
	<br>
	<br>
      <td align="left">
	<a target="_blank">History of Deep Learning. Perceptrons. MLPs. Optimisation, Regularization. </a>
    </tr>
	    
    <!------------------------------------------------------------------------------>
    
    <tr>
      <td rowspan="1"> Week 3
      <td>
	<b>3. Autoencoder, CNN and RNN and their Variants  </b>
	<br>
	<br>
      <td align="left">
	<a target="_blank">Denoising Autoencoder. Adversarial Examples. CNNs. RNNs. LSTMs.</a>
    </tr>  
    <!------------------------------------------------------------------------------>
    
    
	
    <tr>
      <td rowspan="1"> Week 4
      <td>
	<b>4. Transformer</b>
	<br> 
	<br>
     <td align="left">
	<a target="_blank"> Sequence to Sequence with RNNs. Attention. Modules in GPTs. </a>
	      
    </tr>
    <!------------------------------------------------------------------------------>
    
    <tr>
      <td rowspan="1"> Week 5
      <td>
	<b>5. Prompting </b>
	<br> 
	<br>
      <td align="left">
	      <a target="_blank"> Prompting in NLP/CV/vision-language models. Soft/hard Prompts. </a>
    </tr>
    <!------------------------------------------------------------------------------>
    
    <tr>
      <td rowspan="1"> Week 6
      <td>
	<b>6. Model and Dataset Compression</b>
	<br> 
	<br>
      <td align="left">
	<a target="_blank"> Model Compression for DNNs. Dataset Pruning/Distillation</a>
    </tr>
    <!------------------------------------------------------------------------------>

  </tbody>
</table>
<br>

      
<hr>
<h3>Syllabus:</h3>
<ul>
  <li> 1.	Introduction to deep learning (Week 1):
a)	Relation and difference between deep learning and machine learning;
b)	History of deep learning and recent developments;
c)	Overview of popular models and applications;
d)	Basic terminology and concepts: e.g., common learning methods, common network structures, etc.

  <li> 2.	Neural networks, training pipeline and learning strategies (Week 2):
a)	Introduction classic (and basic) multi-layer perceptron neural network (MLP);
b)	Introduction the training pipeline of MLP: learning with backpropagation;
c)	Explain the optimization algorithm: SGD (with momentum), Adam, Adagrad, Second-order optimization, Hessian-free optimization, theoretical analysis of deep neural network model performance;
d)	Explain the different learning strategies: supervised, semi-supervised and unsupervised learning with examples. Include more specific but common learning strategies such as self-supervised learning (including contrastive learning) and transfer learning;
e)	Explain the possible shortcomings of the training pipeline with BP: overfitting, and the solution to mitigate overfitting via regularization (network dropout, data augmentation, etc.)

  <li>3.	Autoencoder, CNN and RNN and their Variants  (Week 3):
a)	Introduction to convolutional / recurrent neural networks: structure, training, and characteristics, including the classic and recent variants;
b)	Introduction to the two basic tasks in computer vision and natural language processing: image and text classification, including the tasks and dataset for the tasks;
c)	Introduction to recent advances of CNNs/RNNs, including the combination of CNNs/RNNs for image captioning, action recognition, etc.;
d)	Explain the reason for the rise and fall of CNNs and RNNs.

  <li> 4.	Transformers (Week 4):
a)	Introduction to self-attention and Transformer model, including advantages over CNNs and RNNs;
b)	Explain the expansion of Transformers to the vision tasks: the non-local block and the ViT. Further introduce the expansion of Transformers to regression-based task (object detection): DETR;
c)	Introduce the recent advances of Transformer models (focus on advances in architecture, leave applications such as to videos and LL(V)Ms to following).

  <li> 5.	Prompting (Week 5):
a)	Introduction to prompting;
b)	Explain the usage of prompting in both NLP and CV domains. 

<li> 6.	Model and Dataset Compression (Week 6)
a)	Introduction to Model Compression including pruning, distillation, and quantization. 
b)	Introduction to Dataset Distillation and Pruning. 

</ul>
	    
 

<br>
<hr>
  <br>
  <br>
<!------------------------------------------------------------------------------>
<!------------------------------------------------------------------------------>
<!------------------------------------------------------------------------------>
<!------------------------------------------------------------------------------>

</div>      
    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script>window.jQuery || document.write('<script src="../../assets/js/vendor/jquery.min.js"><\/script>')</script>
    <script src="bootstrap-3.3.6-dist/js/bootstrap.min.js"></script>
  </body>
  <script type="text/javascript">
    var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
    document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
  </script>
<script type="text/javascript">
  try {
  var pageTracker = _gat._getTracker("UA-13131132-3");
  pageTracker._trackPageview();
  } catch(err) {}</script>

</html>
