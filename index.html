<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html>
  <head>
    <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
    <style type="text/css">
      /* Layout and HTML pieces the work of Jon Barron http://www.cs.berkeley.edu/~barron/ */
      a {
      color: #1772d1;
      text-decoration:none;
      }
      a:focus, a:hover {
      color: #f09227;
      text-decoration:none;
      }
      body,td,th {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px
      }
      tr {
        padding: 20px;
      }
      strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px
      }
      heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 15px;
      font-weight: 700;
      }
      #teaser-td {
      text-align: center;
      margin: auto;
      display: block;
      }
      #teaser {
      width: 200px;
      border-style: none;
      margin-left: auto;
      margin-right: auto;
      }
      hr {
      border: 1px solid black;
      }
    </style>
    <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <title>Joey Tianyi Zhou</title>
    <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-34477541-5', 'auto');
      ga('send', 'pageview');
    </script>

  </head>

  <body>
    <table width="900" border="0" align="center" cellpadding="20">
      <tr>
	      <td>

          <table id="intro" width="100%" align="center" border="0" cellpadding="10">
            <tr>
              <td width="60%" valign="middle"> 
		            <p align="center"><font size="6">Joey Tianyi Zhou (周天异 or 周天異）</font></p>
<p align="justify">
I am the Deputy Director, Principal Scientist II, and Investigator with the <a target="_blank" href="https://www.a-star.edu.sg/cfar/home">A*STAR Centre for Frontier AI Research (CFAR)</a>, Singapore. In CFAR, I am leading ZHOU Group focusing on fundamental AI research. Concurrently, I am holding a joint appointment as the Principal Scientist in the <a target="_blank" href="https://www.catos.sg">Centre for Advanced Technologies in Online Safety (CATOS)</a>.
In CATOS, I lead the "attack team" focused on generating Deepfake and AIGC Videos to fool human users and machine detectors (Please see some demos <a target="_blank" href="https://www.youtube.com/watch?v=cKVEH9E9l6E&t=7s">here</a>). I am also an adjunct faculty member at the <a target="_blank" href="https://cde.nus.edu.sg/ece/about-us/people/adjunct-staff/">National University of Singapore (NUS)</a>.    </br>
I obtained my Ph.D. from Nanyang Technological University (NTU), SG, in 2015. I was a senior research engineer at Sony US Research Center, San Jose, USA.
<br><br>
        My research focus is on how to enhance AI Efficiency and Robustness from a data perspective. An ideal machine learning model shall : (1) be resource-efficient for both inference and training, including computational-efficient and data-efficient; (2)be safe to various perturbations, distribution shifts, and adversarial attacks.
<br><br>
</p>
		            <p align=center>
		           	 <a target="_blank" href="mailto:zhouty@cfar.a-star.edu.sg">A*STAR Email</a> /
				 <a target="_blank" href="mailto:eleztyi@nus.edu.sg">NUS Email</a> / 
				    
				 <a target="_blank" href="files/people.html">People</a> /
				 <a target="_blank" href="files/teachservice.html">NUS Teaching</a> /
                 		 <a target="_blank" href="https://github.com/joeyzhouty/">Github</a> /
				 <a target="_blank" href="https://scholar.google.com/citations?user=cYNqDokAAAAJ&hl=en">Google Scholar</a> / 
		            </p>
              </td>
              <td width="17%">
                <br><br>
  		          <img loading="lazy" width="100%" src="images/zhou_homepage1.png" alt="Joey">
      </td>
            </tr> 
          </table>

          <table id="research group" width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
            <tr>
              <td>
                <font size="4"><span style="color:red">ZHOU</span> (Towards <span style="color:red">Z</span>ero-carbon, <span style="color:red">H</span>igh-reliability, <span style="color:red">O</span>pen-environment, <span style="color:red">U</span>nbiased AI) Research Group in CFAR</font></br>
		                <ul>
                  <li> <b>Scientists:</b> <a target="_blank" href="https://scholar.google.com/citations?user=nRknP8UAAAAJ&hl=en">Ming Yan</a>,
			  <a target="_blank" href="https://he-y.github.io/">Yang He</a>,
			  <a target="_blank" href="https://scholar.google.com/citations?user=WrJKEzEAAAAJ&hl=en">Jiawei Du</a>,
			  <a target="_blank" href="https://zhangxin-xd.github.io">Xin Zhang</a>
		  </li>
                  <li> <b>Engineers:</b>  
				  <a target="_blank" href="https://scholar.google.com/citations?user=geqvEy0AAAAJ&hl=en">Heng Zhao</a>,
                                  <a target="_blank" href="https://uk.linkedin.com/in/hafizalsree">Hafiz Alsree</a>
			  

		 <li> <b>Ph.D students:</b>  Heng Zhao (USTC, BSc; NTU, MSc; 2021 Intake), Yinjie Zhao (NTU, BENG; ACIS scholarship, 2023 Intake), Cheng Shen (UCI, BSc; NYU, MSc; SINGA scholarship, 2023 Intake), Zhiya Tan (SCUT, BA, 2024 Intake)  </li>
		 <li> <b>Interns and Visiting Scholars:~30 students/scholars</b>  </li>
                </ul>
		  
		I am always actively searching for talents interested in the intersections of machine learning, hardware, and quantum computing. The following scholarships will be funded by A*STAR and your Ph.D. degree can be obtained from any Singapore university (e.g., NUS, NTU, SMU, STUD).
	If you want to visit me during your studies, you may apply for a joint Ph.D. scholarship ARAP, or CFAR internship scheme CIARE, ARIA. I can host the visiting students (e.g., CSC program from China) at NUS or A*STAR CFAR. Please feel free to reach out to me. 
	</a> 
		 
                <ul>
                  <li> <b>PhD Scholarships:</b> <a target="_blank" href="https://www.a-star.edu.sg/Scholarships/for-graduate-studies/singapore-international-graduate-award-singa">SINGA</a>,
			<a target="_blank" href="https://www.a-star.edu.sg/Scholarships/for-graduate-studies/a-star-research-attachment-programme-(arap)">ARAP</a>,
			<a target="_blank" href="https://www.a-star.edu.sg/Scholarships/for-graduate-studies/a-star-cis-scholarship">ACIS</a>,
			  <a target="_blank" href="https://aisingapore.org/research/aisg-phd-fellowship-programme/">AISG</a>. I will offer additional allowance on top of any scholarship you have.</li>
                  <li> <b>Master and undergraduate Scholarships:</b>  <a target="_blank" href="https://www.a-star.edu.sg/Scholarships/for-undergraduate-studies">SIPGA</a> </li>
		<li> <b>Interns:</b>  <a target="_blank" href="https://www.a-star.edu.sg/cfar/talent/internship">CIARE</a>, <a target="_blank" href="https://www.a-star.edu.sg/Scholarships/for-undergraduate-studies/a-star-research-internship-award-aria">ARIA</a>.  </li>	
                </ul>
              </td>
            </tr>

	<table id="News" width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
   		 <tr>	    
	            <span style="color:red">New!</span> Call for  interns (available now):  I always seek talented students to join my team. Ph.D. scholarships or official research positions will be prioritized for excellent performers. </br>
   		    <span style="color:red">New!</span> Call for research associates/fellows (available now): I need to hire research associates/fellows in NLP/ML/CV/ domains.  Strong coding and problem-solving skills are preferable.            
    		 </tr>           
 	</table>
 <!--		  
          <table id="CATOS" width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
            <tr>
              <td>
                <font size="4">Joint Appointment in <a target="_blank" href="https://www.catos.sg">Centre for Advanced Technologies in Online Safety (CATOS)</a></font></br>
                <ul>
	          <li>  </li>
                </ul>
              </td>
            </tr>
          </table>
		  
          <table id="teaching" width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
            <tr>
              <td>
                <font size="4">Adjunct Appointment in NUS</font></br>
		You are always welcome to my classes. 
                <ul>
	          <li> Assoc. Prof. (adj.) (2022-present) Teaching duty: <a target="_blank" href="https://nusmods.com/modules/CEG5304/deep-learning-for-digitalization-technologies">[ECG5304] - Deep Learning for Digitalization Technologies</a> </li>
                  <li> Asst. Prof. (adj.) (2019-2022) Teaching duty: <a target="_blank" href="https://nusmods.com/modules/EE6934/deep-learning-advanced">[EE5934/6934] - Deep Learning</a> </li> 
                </ul>
              </td>
            </tr>
          </table>
          
 -->
          <table id="heading" width="120%" align="center" border="0" cellspacing="0" cellpadding="10">
            <tr>
              <td>
                <font size="4">Research</font>
              </td>
            </tr>
          </table>
 <!-- 
comments out
      	  <table id="workworkwork" width="100%" align="center" cellpadding="10" style="background-color:#6AFF1C4D;">
            <tr>
                <td colspan="2" style="padding-bottom:0;">
                  <font size="3"><b>Projects</b></font><hr>
                </td>
            </tr>
            <tr id="multi-goal">
              <td width="25%" valign="top">
                <img loading="lazy" id="teaser" src="teasers/pickandplace.gif">
              </td>
                
              <td width="75%" valign="center">
                <p>
                      <b>Multi-goal reinforcement learning</b><br>
                      <strong>TL;DR:</strong> We propose new methods and environments for multi-goal settings with sparse rewards.<br>
                      <i>Keywords: sparse rewards, sample efficient.</i>
                      <a target="_blank" href="files/multigoal.html">[project page]</a>
                </p>
              </td>
          </tr>

            <tr id="text-games">
              <td width="25%" valign="top">
                <img loading="lazy" id="teaser" src="teasers/zorkgame.gif">
              </td>
                
              <td width="75%" valign="center">
                <p>
                      <b>Text-based games</b><br>
                      <strong>TL;DR:</strong> We consider the task of learning control policies for text-based games.<br>
                      <i>Keywords: knowledge graphs, attention, RL, hierarchical RL.</i>
                      <a target="_blank" href="files/textgames.html">[project page]</a>
                </p>
              </td>
          </tr>
          
          <tr id="qanda">
            <td width="25%" valign="top">
              <img loading="lazy" id="teaser" src="teasers/QA-retriever-reader.png">
            </td>
              
            <td width="75%" valign="center">
              <p>
                    <b>Question & Answering</b><br>
                    <strong>TL;DR:</strong> We consider the reasoning process for question and answering problems.<br>
                    <i>Keywords: graphs, graph neural networks, knowledge graphs.</i>
                    <a target="_blank" href="files/qanda.html">[project page]</a>
              </p>
            </td>
        </tr>
    --> 
         
<table id="workworkwork" width="100%" align="center" cellpadding="10" style="background-color:#76E4E84D;">
            <tr>
                <td colspan="2" style="padding-bottom:0;">
                  <font size="3"><b>Data-Centric AI</b></font><hr>
                </td>    
	 </tr>
	<tr id="BreakingClass">
            <td width="75%" valign="center">
              <p>
                <b><a target="_blank" href="https://openreview.net/pdf?id=X0CxfByJog">Breaking Class Barriers: Efficient Dataset Distillation via Inter-Class Feature Compensator</a></b><br>
                Xin Zhang, Jiawei Du,  Ping Liu, <strong>Joey Tianyi Zhou*</strong> <br>
                <i>In ICLR 2025  </i><br>
              </p>
            </td>
        </tr>
       <tr id="DWA">
            <td width="75%" valign="center">
              <p>
                <b><a target="_blank" href="https://openreview.net/pdf?id=uwSaDHLlYc">Diversity-Driven Synthesis: Enhancing Dataset Distillation through Directed Weight Adjustment</a></b><br>
                Jiawei Du, Xin Zhang, Juncheng Hu, Wenxin Huang, <strong>Joey Tianyi Zhou*</strong> <br>
                <i>In NeurIPS 2024 (Spotlight Paper) </i><br>
              </p>
            </td>
        </tr>
	<tr id="EVA">
            <td width="75%" valign="center">
              <p>
                <b><a target="_blank" href="https://dl.acm.org/doi/10.1145/3664647.3681592">Evolution-aware VAriance (EVA) Coreset Selection for Medical Image Classification</a></b><br>
                Yuxin Hong, Xiao Zhang, Xin Zhang, <strong>Joey Tianyi Zhou*</strong> <br>
                <i>In ACM MM 2024 (Best Paper Nomination) </i><br>
              </p>
            </td>
        </tr>
        <tr id="TDDS">
            <td width="75%" valign="center">
              <p>
                <b><a target="_blank" href="https://openreview.net/pdf?id=tTPIk5I2Qk">Spanning Training Progress: Temporal Dual-Depth Scoring (TDDS) for Enhanced Dataset Pruning</a></b><br>
                Xin Zhang, Jiawei Du, Weiying Xie, Yunsong Li, <strong>Joey Tianyi Zhou*</strong> <br>
                <i>In CVPR 2024 </i><br>
              </p>
            </td>
        </tr>
	
	<tr id="MultiDataConden">
            <td width="75%" valign="center">
              <p>
                <b><a target="_blank" href="https://openreview.net/forum?id=FVhmnvqnsI">Multisize Dataset Condensation</a></b><br>
                Yang He, Lingao Xiao, <strong>Joey Tianyi Zhou*</strong>, Ivor Tsang <br>
                <i>In ICLR 2024 (Oral, 1.2%)</i><br>
              </p>
            </td>
        </tr>
<!-- 	<tr id="Prun4Vit">
            <td width="75%" valign="center">
              <p>
                <b><a target="_blank" href="https://openreview.net/pdf?id=7Ol6foUi1G">Data-independent Module-aware Pruning for Hierarchical Vision Transformers</a></b><br>
                Yang He,  <strong>Joey Tianyi Zhou*</strong> <br>
                <i>In ICLR 2024</i><br>
              </p>
            </td>
        </tr> -->
	
           </tr>
	<tr id="DataPrune">
            <td width="75%" valign="center">
              <p>
                <b><a target="_blank" href="https://openreview.net/pdf?id=AlTyimRsLf">You Only Condense Once: Two Rules for Pruning Condensed Datasets</a></b><br>
                Yang He, Lingao Xiao, <strong>Joey Tianyi Zhou*</strong> <br>
                <i>In NeurIPS 2023</i><br>
              </p>
            </td>
        </tr>
	<tr id="Datadistill">
            <td width="75%" valign="center">
              <p>
                <b><a target="_blank" href="https://openreview.net/pdf?id=c9fXCzR5fK">Sequential Subset Matching for Dataset Distillation</a></b><br>
                Jiawei Du, Qin Shi, <strong>Joey Tianyi Zhou*</strong> <br>
                <i>In NeurIPS 2023</i><br>
              </p>
            </td>
        </tr>
	 <tr id="SAF">
            <td width="75%" valign="center">
              <p>
                <b><a target="_blank" href="https://openreview.net/forum?id=xK6wRfL2mv7">Sharpness-aware training for free</a></b><br>
                Jiawei Du, Daquan Zhou, Jiashi Feng, Vincent Y. F. Tan, <strong>Joey Tianyi Zhou</strong>, <br>
                <i>In NeurIPS 2022</i><br>
              </p>
            </td>
        </tr>
 <!-- 
comments out
        <tr id="FPGAs">
            <td width="75%" valign="center">
              <p>
                <b><a target="_blank" href="">Accelerating attention mechanism on FPGAs based on efficient reconfigurable systolic array</a></b><br>
                Wenhua Ye, Xu Zhou,  <strong>Joey Tianyi Zhou</strong>, Cen Chen and Kenli Li, <br>
                <i>In ACM Transactions on Embedded Computing Systems 2022</i><br>
              </p>
            </td>
        </tr>
-->
	
<!--         <tr id="RCT">
            <td width="75%" valign="center">
              <p>
                <b><a target="_blank" href="">RCT: Resource Constrained Training for Edge AI</a></b><br>
                Tian Huang, Tao Luo, Ming Yan and <strong>Joey Tianyi Zhou</strong>, Rick Siow Mong Goh, <br>
                <i>In IEEE Transactions on Neural Networks and Learning Systems 2022</i><br>
              </p>
            </td>
          </tr> -->
	
	
<!--          <tr id="SNN with Radix">
            <td width="75%" valign="center">
              <p>
                <b><a target="_blank" href="">Efficient Spiking Neural Networks with Radix Encoding</a></b><br>
                Zhehui Wang, Tao Luo, Rick Siow Mong Goh, and  <strong>Joey Tianyi Zhou</strong><br>
                <i>In IEEE Transactions on Neural Networks and Learning Systems 2022</i><br>
              </p>
            </td>
          </tr> -->
 <!-- 
comments out
          <tr id="racetrack">
            <td width="75%" valign="center">
              <p>
                <b><a target="_blank" href="">Hardware-software co-exploration with racetrack memory based in-memory computing for CNN inference in embedded systems</a></b><br>
                Benjamin Chen Ming Choong, Tao Luo, Cheng Liu, Bingsheng He, Wei Zhang, and <strong>Joey Tianyi Zhou</strong><br>
                <i>In Journal of Systems Architecture 2022</i><br>
              </p>
            </td>
          </tr>
-->	  
         <tr id="EDCompress">
            <td width="75%" valign="center">
              <p>
                <b><a target="_blank" href="">EDCompress: Energy-Aware Model Compression for Dataflows</a></b><br>
                Zhehui Wang, Tao Luo, Rick Siow Mong Goh, and <strong>Joey Tianyi Zhou*</strong><br>
                <i>In IEEE Transactions on Neural Networks and Learning Systems 2022</i><br>
              </p>
            </td>
          </tr>
		  
<!--           <tr id="Pan_TON">   
            <td width="75%" valign="center">
              <p>
                <b><a target="_blank" href="https://www.computer.org/csdl/journal/nt/5555/01/09606219/1ymEoKr8t3y">Utility Optimal Thread Assignment and Resource Allocation in Multi-Server Systems</a></b><br>
                Pan Lai, Rui Fan, Xiao Zhang, Wei Zhang, Fang Liu, <strong>Joey Tianyi Zhou</strong><br>
                <i>In IEEE/ACM Transactions on Networking 2021</i><br>
              </p>
            </td>
          </tr> -->
	  <tr id="Evo_compression">
  
		  
          <tr id="DATNet">
         
            <td width="75%" valign="center">
              <p>
                <b><a target="_blank" href="https://ieeexplore.ieee.org/document/8778733">Dual Adversarial Neural Transfer for Sequence Labeling</a></b><br>
                <strong>Joey Tianyi Zhou</strong>, Hao Zhang, Di Jin, Xi Peng<br>
                <i>In IEEE Transactions on Pattern Analysis and Machine Intelligence 2021</i><br>
              </p>
            </td>
          </tr>
		  
	 <tr id="Multi-sourceMeta">
         
            <td width="75%" valign="center">
              <p>
                <b><a target="_blank" href="https://aclanthology.org/2020.acl-main.654/">Multi-source Meta Transfer for Low Resource Multiple Choice Question Answering</a></b><br>
                Ming Yan, Hao Zhang, Di Jin and <strong>Joey Tianyi Zhou*</strong><br>
                <i>In ACL 2020</i><br>
              </p>
            </td>
          </tr>

          <tr id="HybridDeep">
         
            <td width="75%" valign="center">
              <p>
                <b><a target="_blank" href="https://www.sciencedirect.com/science/article/abs/pii/S0004370219301493">A Deep Learning Framework for Hybrid Heterogeneous Transfer Learning</a></b><br>
                <strong>Joey Tianyi Zhou</strong>, Sinno Jialin Pan, Ivor W. Tsang.<br>
                <i>In Artificial Intelligence 2019</i><br>
              </p>
            </td>
          </tr>
		  
          <tr id="Multi_Hetro">
         
            <td width="75%" valign="center">
              <p>
                <b><a target="_blank" href="https://jmlr.org/papers/v20/13-580.html">Multi-class Heterogeneous Domain Adaptation</a></b><br>
                <strong>Joey Tianyi Zhou</strong>, Ivor W. Tsang, Sinno Jialin Pan and Mingkui Tan<br>
                <i>In Journal of Machine Learning Research 2019</i><br>
              </p>
            </td>
          </tr>
	
<!--          
            <td width="75%" valign="center">
              <p>
                <b><a target="_blank" href="https://ieeexplore.ieee.org/document/9492169">Evolutionary Multi-Objective Model Compression for Deep Neural Networks</a></b><br>
                Zhehui Wang, Tao Luo, Miqing Li, <strong>Joey Tianyi Zhou</strong>, Rick Siow Mong Goh, Liangli Zhen<br>
                <i>In IEEE Computational Intelligence Magazine 2021</i><br>
              </p>
            </td>
          </tr>
		  
	 <tr id="adpprecsion">        
            <td width="75%" valign="center">
              <p>
                <b><a target="_blank" href="https://ieeexplore.ieee.org/document/9355751">Adaptive Precision Training for Resource Constrained Devices</a></b><br>
                Tian Huang, Tao Luo, <strong>Joey Tianyi Zhou</strong><br>
                <i>In ICDCS 2020</i><br>
              </p>
            </td>
          </tr>  
          <tr id="Par_multi">
         
            <td width="75%" valign="center">
              <p>
                <b><a target="_blank" href="https://www.computer.org/csdl/journal/tp/5555/01/09258396/1oHhk9BNESA">Deep Partial Multi-View Learning</a></b><br>
                Changqing Zhang, Yajie Cui, Zongbo Han, <strong>Joey Tianyi Zhou*</strong>, Huazhu Fu and Qinghua Hu <br>
                <i>In IEEE Transactions on Pattern Analysis and Machine Intelligence 2021</i><br>
              </p>
            </td>
          </tr>
          <tr id="APT">
            <td width="75%" valign="center">
              <p>
                <b><a target="_blank" href="">APT: The master-copy-free training method for quantised neural network on edge devices</a></b><br>
                Tian Huang, Tao Luo,  and <strong>Joey Tianyi Zhou</strong><br>
                <i>In Journal of Parallel and Distributed Computing 2022</i><br>
              </p>
            </td>
          </tr>
	<tr id="Efficient Sharpness">
            <td width="75%" valign="center">
              <p>
                <b><a target="_blank" href="https://arxiv.org/pdf/2204.11423.pdf">Efficient Sharpness-aware Minimization for Improved Training of Neural Networks</a></b><br>
               Jiawei Du, Hanshu Yan, Jiashi Feng, <strong>Joey Tianyi Zhou*</strong>, Liangli Zhen, Rick Siow Mong Goh, Vincent YF Tan <br>
                <i>In ICLR 2022</i><br>
              </p>
            </td>
          </tr>
--> 		

</table>











		  

<table id="workworkwork" width="100%" align="center" cellpadding="10" style="background-color:#AD8FFF4D;">
            <tr>
                <td colspan="2" style="padding-bottom:0;">
                  <font size="3"><b> Safe and Reliable AI </b></font><hr>
                </td>
            </tr>
      <tr id="LLM_evidence">
            <td width="75%" valign="center">
              <p>
                <b><a target="_blank" href="https://arxiv.org/abs/2502.00290">	Estimating LLM Uncertainty with Evidence</a></b><br>
              Huan Ma, Jingdong Chen, <strong>Joey Tianyi Zhou</strong>, Guangyu Wang, Changqing Zhang<br>
                <i>arxiv</i><br>
              </p>
            </td>
          </tr>

	<tr id="socialbias">
            <td width="75%" valign="center">
              <p>
                <b><a target="_blank" href="https://aclanthology.org/2025.findings-naacl.39/">Identifying and Mitigating Social Bias Knowledge in Language Models</a></b><br>
              Ruizhe Chen, Yichen Li, Jianfei Yang, Yang Feng,  <strong>Joey Tianyi Zhou</strong>, Jian Wu, Zuozhu Liu,<br>
                <i>In NAACL 2025</i><br>
              </p>
            </td>
          </tr>
         <tr id="Shortcuts">
            <td width="75%" valign="center">
              <p>
                <b><a target="_blank" href="https://aclanthology.org/2024.emnlp-main.834/">Shortcuts Arising from Contrast: Towards Effective and Lightweight Clean-Label Attacks in Prompt-Based Learning</a></b><br>
              Xiaopeng Xie, Ming Yan, Xiwen Zhou, Chenlong Zhao, Suli Wang, Yong Zhang, and <strong>Joey Tianyi Zhou*</strong><br>
                <i>In EMNLP 2024</i><br>
              </p>
            </td>
          </tr>

	
	<tr id="MetaFL">
            <td width="75%" valign="center">
              <p>
                <b><a target="_blank" href="https://arxiv.org/abs/2209.14851">Meta Knowledge Condensation for Federated Learning</a></b><br>
              Ping Liu, Xin Yu, and <strong>Joey Tianyi Zhou*</strong><br>
                <i>In ICLR 2023</i><br>
              </p>
            </td>
          </tr>
	
          <tr id="Trusted Multi-View">
            <td width="75%" valign="center">
              <p>
                <b><a target="_blank" href="https://arxiv.org/pdf/2204.11423.pdf">Trusted Multi-View Classification with Dynamic Evidential Fusion</a></b><br>
               Zongbo Han, Changqing Zhang, Huazhu Fu and <strong>Joey Tianyi Zhou</strong><br>
                <i>In IEEE Transactions on Pattern Analysis and Machine Intelligence 2022</i><br>
              </p>
            </td>
          </tr>
		  
		  
          <tr id="KmeansNet">
            <td width="75%" valign="center">
              <p>
                <b><a target="_blank" href="https://www.jmlr.org/papers/v23/19-497.html">XAI Beyond Classiﬁcation: Interpretable Neural Clustering</a></b><br>
               Xi Peng, Yunfan Li, Ivor Tsang, Hongyuan Zhu, Jiancheng Lv, and  <strong>Joey Tianyi Zhou</strong><br>
                <i>In  Journal of Machine Learning Research  2022</i><br>
              </p>
            </td>
          </tr>
		  
          <tr id="PointBA">
         
            <td width="75%" valign="center">
              <p>
                <b><a target="_blank" href="https://openaccess.thecvf.com/content/ICCV2021/papers/Li_PointBA_Towards_Backdoor_Attacks_in_3D_Point_Cloud_ICCV_2021_paper.pdf">PointBA: Towards Backdoor Attacks in 3D Point Cloud</a></b><br>
               Xinke Li, Zhiru Chen, Yue Zhao, Zekun Tong, Yabang Zhao, Andrew Lim, <strong>Joey Tianyi Zhou</strong><br>
                <i>In ICCV 2021</i><br>
              </p>
            </td>
          </tr>
           
          <tr id="Trusted_Multi">
         
            <td width="75%" valign="center">
              <p>
                <b><a target="_blank" href="https://openreview.net/forum?id=OOsR8BzCnl5">Trusted Multi-View Classification</a></b><br>
               Zongbo Han, Changqing Zhang, Huazhu Fu, <strong>Joey Tianyi Zhou</strong><br>
                <i>In ICLR 2021</i><br>
              </p>
            </td>
          </tr>
		  
          <tr id="Trusted_reg">
         
            <td width="75%" valign="center">
              <p>
                <b><a target="_blank" href="https://arxiv.org/abs/2111.08456">Trustworthy Multimodal Regression with Mixture of Normal-inverse Gamma Distributions</a></b><br>
              Huan Ma, Zongbo Han, Changqing Zhang, Huazhu Fu,  <strong>Joey Tianyi Zhou</strong> and Qinghua Hu <br>
                <i>In NeurIPS 2021</i><br>
              </p>
            </td>
          </tr>
	<tr id="bertattack">
         
            <td width="75%" valign="center">
              <p>
                <b><a target="_blank" href="https://ojs.aaai.org/index.php/AAAI/article/view/6311/6167">Is BERT Really Robust? A Strong Baseline for Natural Language Attack on Text Classification and Entailment</a></b><br>
               Di Jin, Zhijing Jin, <strong>Joey Tianyi Zhou</strong>, Peter Szolovits<br>
                <i>In AAAI 2020</i><br>
              </p>
            </td>
          </tr>

          <tr id="Metaattack">
         
            <td width="75%" valign="center">
              <p>
                <b><a target="_blank" href="https://openreview.net/forum?id=Skxd6gSYDS">Query-efficient Meta Attack to Deep Neural Networks</a></b><br>
               Jiawei Du, Hu Zhang, <strong>Joey Tianyi Zhou*</strong>, Yi Yang, Jiashi Feng<br>
                <i>In ICLR 2020</i><br>
              </p>
            </td>
          </tr>


          </table>

          <table id="workworkwork" width="100%" align="center" cellpadding="10" style="background-color:#E876784D;">
            <tr>
                <td colspan="2" style="padding-bottom:0;">
                  <font size="3"><b>Large Foundation Model Framework</b></font><hr>
                </td>
            </tr>

<tr id="rethinkagent">
        <td width="75%" valign="center">
              <p>
                <b><a target="_blank" href="https://arxiv.org/abs/2505.17673">Rethinking Agent Design: From Top-Down Workflows to Bottom-Up Skill Evolution</a></b><br>
                Jiawei Du, Jinlong Wu, Chen Yuzheng, Yucheng Hu, Bing Li,<strong>Joey Tianyi Zhou</strong><br>
                <i>Arxiv</i><br>
              </p>
            </td>
          </tr> 


		  

	<tr id="KPL">
        <td width="75%" valign="center">
              <p>
                <b><a target="_blank" href="https://arxiv.org/abs/2501.11231">KPL: Training-Free Medical Knowledge Mining of Vision-Language Models</a></b><br>
                Jiaxiang Liu, Tianxiang Hu, Jiawei Du, Ruiyuan Zhang, <strong>Joey Tianyi Zhou</strong>, Zuozhu Liu<br>
                <i>In EMNLP 2024</i><br>
              </p>
            </td>
          </tr> 
		  
	<tr id="word2pix">
            <td width="75%" valign="center">
              <p>
                <b><a target="_blank" href="https://arxiv.org/abs/2108.00205">Word2Pix: Word to Pixel Cross-Attention Transformer in Visual Grounding</a></b><br>
               Heng Zhao, <strong>Joey Tianyi Zhou*</strong>, Yew-Soon Ong,<br>
                <i>In IEEE Transactions on Neural Networks and Learning Systems 2024</i><br>
              </p>
            </td>
          </tr>   
		  
	<tr id="difformer">
            <td width="75%" valign="center">
              <p>
                <b><a target="_blank" href="https://ieeexplore.ieee.org/abstract/document/10177239/">Difformer: Multi-resolutional differencing transformer with dynamic ranging for time series analysis</a></b><br>
               Bing Li, Wei Cui, Le Zhang, Ce Zhu, Wei Wang, Ivor W Tsang, <strong>Joey Tianyi Zhou</strong><br>
                <i>In IEEE Transactions on Pattern Analysis and Machine Intelligence 2023</i><br>
              </p>
            </td>
          </tr> 
		  
          <tr id="counting">
            <td width="75%" valign="center">
              <p>
                <b><a target="_blank" href="https://ieeexplore.ieee.org/document/9346018/authors#authors">Locality-Aware Crowd Counting</a></b><br>
                <strong>Joey Tianyi Zhou</strong>, Le Zhang, Du Jiawei, Xi Peng, Zhiwen Fang, Zhe Xiao, Hongyuan Zhu<br>
                <i>In IEEE Transactions on Pattern Analysis and Machine Intelligence 2021</i><br>
              </p>
            </td>
          </tr> 
		  
         <tr id="Span">
            <td width="75%" valign="center">
              <p>
                <b><a target="_blank" href="https://www.computer.org/csdl/journal/tp/5555/01/09361191/1rseyuWCjXW">Natural Language Video Localization: A Revisit in Span-based Question Answering Framework</a></b><br>
                Hao Zhang, Aixin Sun, Wei Jing, Liangli Zhen, <strong>Joey Tianyi Zhou*</strong> and Rick Siow Mong Goh<br>
                <i>In IEEE Transactions on Pattern Analysis and Machine Intelligence 2020</i><br>
              </p>
            </td>
          </tr> 
         
  

         <tr id="AnomalyNet">
         
            <td width="75%" valign="center">
              <p>
                <b><a target="_blank" href="https://ieeexplore.ieee.org/document/8649753">AnomalyNet: An Anomaly Detection Network for Video Surveillance</a></b><br>
              <strong>Joey Tianyi Zhou</strong>, Jiawei Du, Hongyuan Zhu, Xi Peng, Yong Liu, Rick Siow Mong Goh <br>
                <i>In IEEE Transactions on Information Forensics & Security 2019</i><br>
              </p>
            </td>
          </tr> 

</table>

          <hr>
<table id="service" width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
              <td>
                <font size="4">Academic Service</font></br>
              </td>
            </tr>
            <tr>
              <td width="100%" valign="top">
		       Associate Editor/Editorial Board:
                 <ul>
		<li> 2025-present <a target="_blank" href="https://link.springer.com/journal/11263/editorial-board">International Journal of Computer Vision (IJCV)</a> </li>	 
                  <li> 2024-present <a target="_blank" href="https://www.journals.elsevier.com/artificial-intelligence/editorial-board">Artificial Intelligence Journal(AIJ)</a> </li>
                  <li> 2022-present <a target="_blank" href="https://cis.ieee.org/publications/t-emerging-topics-in-ci/tetci-editors-and-associate-editors">IEEE Transactions on Emerging Topics in Computational Intelligence (TETCI)</a> </li>
		  <li> 2020-2023 <a target="_blank" href="https://digital-library.theiet.org/journals/iet-ipr/editorial-board">  IET Image Processing  </a> </li>
		  <li> 2019-2023 <a target="_blank" href="https://ieeeaccess.ieee.org/">  IEEE Access  </a> </li>	 
                </ul>
		     Senior/Area Chair:
                 <ul>
		  <li> 2024,2025  <a target="_blank" href=https://neurips.cc/Conferences/2024/CallForPapers"">NeurIPS</a> </li>
		  <li> 2023,2024,2025  <a target="_blank" href=https://iclr.cc/Conferences/2024/CallForPapers"">ICLR</a> </li>
		  <li> 2023,2024,2025  <a target="_blank" href=https://icml.cc/Conferences/2024/Dates"">ICML</a> </li>
		  <li> 2025  <a target="_blank" href="https://kdd2025.kdd.org/">KDD</a> </li> 
		  <li> 2024  <a target="_blank" href="https://ijcai24.org/">IJCAI</a> </li>
		  <li> 2021  <a target="_blank" href="">ICME</a> </li> 
			 
                </ul>
		     Programme Chair/Organising Committee:
                 <ul>
		<li> Associate Programme Chair <a target="_blank" href="https://2025.ijcai.org/program-committee/">the 34th International Joint Conference on Artificial Intelligence (IJCAI 2025) </a> </li>
		<li> Industry Programme Chair <a target="_blank" href="https://2025.ijcnn.org/about/organizing-committee">International Joint Conference on Neural Networks (IJCNN 2025) </a> </li>
		<li> Workshop Chair <a target="_blank" href="https://ieeecai.org/2024/">The 2024 IEEE Conference on Artificial Intelligence (IEEE CAI 2024) </a> </li>
                  <li> 2020-present <a target="_blank" href="https://eai-icdcs.github.io/">International Workshop on Efficient Artificial Intelligence For Edge Computing (EAI) at ICDCS</a> </li>
                </ul>
		     Membership:
                 <ul> 
                  <li> IEEE Senior Member </li>
		  <li> INNS Member, AICI Section Technical Coordinator </li>
		  <li> EAI Distinguished Member </li> 
		</ul>
              </td>
            </tr>
</table>

          <hr>
<table id="other_stuff" width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
            <tr>
              <td>
                <font size="4">Awards</font></br>
              </td>
            </tr>
            <tr>
              <td width="100%" valign="top">
                <ul>
		<li> <a target="_blank" href="">2024 ACM MM Best Paper Nomination</a> </li>
		<li> <a target="_blank" href="https://ecebm.com/2023/10/04/stanford-university-names-worlds-top-2-scientists-2023/">World's Top 2% Scientists</a> </li>
		<li> <a target="_blank" href="https://www.a-star.edu.sg/cfar/news/news/features/IEEE-smartcity-2022-best-paper-award">2022 IEEE SmartCity Best Paper</a> </li>
                 <li> <a target="_blank" href="">2020 National Research Foundation Fellow (NRF-F) Finalist</a> </li>	
		<li> <a target="_blank" href="">2019 IEEE Innovation Spotlight Paper</a> </li>
		  <li> <a target="_blank" href="">2019 ICCV Hands Challenge: Runner-up Prize</a> </li>
                  <li> <a target="_blank" href="">2019 BOOM workshop on IJCAI: Best Paper Award</a> </li>
	          <li> <a target="_blank" href="">2017 NeurIPS Best Reviewer</a> </li>
		<li> <a target="_blank" href="">2016 BeyondLabeler workshop on IJCAI: Best Paper Award</a> </li>
	       <li> <a target="_blank" href="">2016 ECCV Best Student Paper Nomination</a> </li>
                </ul>
              </td>
            </tr>
</table>

          <hr>
          <table id="Funding" width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
  <tr>
              <td>
                <font size="4">Competitive Funding Award</font></br>
              </td>
            </tr>
            <tr>
              <td width="100%" valign="top">
                <ul>
		<li> Digital Trust Centre Innovation Grant (No:DTC-IGC-02)： <a target="_blank" href="">Reassemble Data Before Sharing: Innovative Privacy-Preserved Data-Sharing Solutions for Cloud Services</a>, PI, Jul. 15 2025 - Jul. 14 2026</li>
		<li> RIE2025 Japan-Singapore Joint Grant (No:R24I6IR133): <a target="_blank" href="">Breaking Multimodal Correspondence: Crafting Safer and Fairer Multimodal AIGC</a>, PI, Apr. 1 2025 - 31 Mar. 2028 </li>
		<li> AISG 2024 Research Grant (No. AISG3-RP-2024-033):<a target="_blank" href=""> Sequential Deepfake Attribution,</a> PI, 06 Jan. 2025- 05 Jan. 2028 </li>
		<li> National Multimodal LLM Programme (No. AISG-NMLP-2024-003):  <a target="_blank" href="">Privacy^2: Fine-Tuning Encapsulated LLMs to Downstream Tasks Without Peeking on Private Data,</a> Co-PI, 01 Apr. 2025- 31 Mar. 2028</li>
                <li> A*STAR Central Research Funding:<a target="_blank" href=""> Tiny Machine Learning,</a> PI, 2020-2026 </li>
		</ul>
              </td>
            </tr>
           
          </table>

          <table id="thanks" width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
              <td>
                <br>
                <p align="right"><font size="2">
                  <a href="http://www.cs.berkeley.edu/~barron/">(imitation is the sincerest form of flattery)</a>
                  </font>
                </p>
              </td>
            </tr>
          </table>

        </td>
      </tr>
    </table>
  </body>
</html>
